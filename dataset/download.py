import os
import time
import json
import shutil
import subprocess
import pandas as pd

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
METADATA_FILE = "../../data/dataset/metadata.csv"
PRIMARY_DIR = "I:/downloaded_videos"
SECONDARY_DIR = "D:/downloaded_videos"
FAILED_LOG = "download_failed.txt"

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(PRIMARY_DIR, exist_ok=True)
os.makedirs(SECONDARY_DIR, exist_ok=True)

# ğŸ’¾ ë©”íƒ€ë°ì´í„° ë¡œë“œ
df_meta = pd.read_csv(METADATA_FILE)
df_meta = df_meta.dropna(subset=["youtube_id"])  # ê²°ì¸¡ ì œê±°
df_meta = df_meta.set_index("video_id")

# ìœ íš¨í•œ video_id ëª©ë¡
video_ids = df_meta.index.tolist()

# ë””ìŠ¤í¬ ìš©ëŸ‰ ì²´í¬
def has_enough_space(path, required_bytes=300 * 1024 * 1024):
    try:
        total, used, free = shutil.disk_usage(path)
        return free > required_bytes
    except:
        return False

# ìœ íš¨í•œ ì˜ìƒ ì²´í¬
def is_valid_video_file(path, min_size_kb=100):
    return os.path.exists(path) and os.path.getsize(path) > min_size_kb * 1024

# ì‹¤íŒ¨ ê¸°ë¡
def log_failure(vid, reason):
    with open(FAILED_LOG, "a", encoding="utf-8") as f:
        f.write(f"{vid}: {reason}\n")

# ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def download_video(youtube_id, out_path, vid):
    url = f"https://www.youtube.com/watch?v={youtube_id}"
    print(f"[INFO] Downloading {url} â†’ {out_path}")
    try:
        subprocess.run([
            "yt-dlp", "-f", "mp4", "-o", out_path, url
        ], check=True)
        return True
    except subprocess.CalledProcessError as e:
        reason = f"yt-dlp error: {e}"
        log_failure(vid, reason)
        print(f"[ERROR] {vid} failed: {reason}")
        return False

# ê¸°ì¡´ì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” video_id ëª©ë¡
def get_existing_video_ids():
    all_ids = set()
    for folder in [PRIMARY_DIR, SECONDARY_DIR]:
        if os.path.exists(folder):
            for file in os.listdir(folder):
                if file.endswith(".mp4"):
                    if is_valid_video_file(os.path.join(folder, file)):
                        all_ids.add(os.path.splitext(file)[0])
    return all_ids

existing_ids = get_existing_video_ids()

# ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
for vid in video_ids:
    if vid in existing_ids:
        print(f"[SKIP] {vid} already exists.")
        continue

    print(f"\n[â–¶] Processing {vid}...")

    try:
        youtube_id = df_meta.loc[vid]["youtube_id"]
    except KeyError:
        log_failure(vid, "video_id not in metadata")
        print(f"[WARNING] {vid} not found in metadata")
        continue

    out_filename = f"{vid}.mp4"
    out_path = os.path.join(PRIMARY_DIR, out_filename)
    fallback_path = os.path.join(SECONDARY_DIR, out_filename)

    time.sleep(2)  # ë„ˆë¬´ ë¹ ë¥´ê²Œ ìš”ì²­í•˜ì§€ ì•Šë„ë¡ delay

    if has_enough_space(PRIMARY_DIR):
        success = download_video(youtube_id, out_path, vid)
        if not success and has_enough_space(SECONDARY_DIR):
            download_video(youtube_id, fallback_path, vid)
    elif has_enough_space(SECONDARY_DIR):
        download_video(youtube_id, fallback_path, vid)
    else:
        log_failure(vid, "Insufficient disk space")
        print(f"[ERROR] Not enough disk space for {vid}")
